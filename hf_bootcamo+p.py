# -*- coding: utf-8 -*-
"""HF BOOTCAMO+P.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yfj2Pmge1cnpkYZT_DElxdJtEPclXyUb

# 1 TEXT GENERATION MODEL (MODEL- gpt2)
"""

from transformers import pipeline
generator = pipeline("text-generation", model= 'gpt2')
response = generator('what is Hugging Face', max_length = 50, num_return_sequences=1)
print(response[0]['generated_text'])





!nvidia-smi

"""# 2 NER (NAMED ENTITY RECOGNITION)"""

from transformers import pipeline
ner = pipeline('ner', grouped_entities=True)
entities = ner('Hugging face is based on NYC and partner with Google with $200 dollar price')
print(entities)

"""#3 SENTIMENT ANLAYSIS"""

!pip install transformers datasets

from transformers import pipeline

classifier = pipeline('sentiment-analysis')
result = classifier(' I love Hugging Face library very much, it is so nice')
print(result)

from transformers import pipeline

classifier = pipeline('sentiment-analysis')
result = classifier(' The food is not testy')
print(result)

!pip install gradio

import gradio as gr

from transformers import pipeline

classifier = pipeline('sentiment-analysis')

def analyze_sentiment(text):
  return classifier(text)[0]['label']

gr.Interface(fn = analyze_sentiment, inputs='text', outputs='text').launch()

from diffusers import StableDiffusionPipeline
import torch

model_id = "sd-legacy/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
pipe = pipe.to("cuda")

prompt = "a photo of an astronaut riding a horse on mars"
image = pipe(prompt).images[0]

image.save("astronaut_rides_horse.png")

from diffusers import StableDiffusionPipeline
import torch

model_id = "sd-legacy/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
pipe = pipe.to("cuda")

prompt = "beautiful girl walking in street light with her pet dog"
image = pipe(prompt).images[0]

image.save("beautifull.png")

!nvidia-smi

import gradio as gr
from diffusers import StableDiffusionPipeline
import torch

model_id = "sd-legacy/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    use_auth_token=True
)
pipe = pipe.to("cuda")

def generated_image(prompt):
    image=pipe(prompt).images[0]
    return image

gr.Interface(
    fn=generated_image,
    inputs=gr.Textbox(label='Enter your prompt',placeholder='beautiful girl walking in street light with her pet dog'),
    outputs=gr.Image(type='pil', label='Generated Image'),
    title = 'Divesh Patil Text - Image Generator',
    description = 'Enter your prompt and see your generated image'
).launch()

import gradio as gr
from diffusers import StableDiffusionPipeline
import torch

model_id = "sd-legacy/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    use_auth_token=True
)
pipe = pipe.to("cuda")

def generated_image(prompt):
    image=pipe(prompt).images[0]
    return image

gr.Interface(
    fn=generated_image,
    inputs=gr.Textbox(label='Enter your prompt',placeholder='beautiful girl walking in street light with her pet dog'),
    outputs=gr.Image(type='pil', label='Generated Image'),
    title = 'Divesh Patil Text - Image Generator',
    description = 'Enter your prompt and see your generated image'
).launch()